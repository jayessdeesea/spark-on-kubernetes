apiVersion: v1
kind: Pod
metadata:
  name: spark-pi
  namespace: spark-namespace
spec:
  restartPolicy: Never
  serviceAccountName: spark-service-account
  securityContext:
    runAsUser: 185
    runAsGroup: 185
    fsGroup: 185
  containers:
  - name: spark
    image: docker.io/apache/spark:3.5.0
    command: 
      - "/opt/spark/bin/spark-submit"
    args:
      - "--master"
      - "k8s://https://kubernetes.docker.internal:6443"
      - "--deploy-mode"
      - "cluster"
      - "--name"
      - "spark-pi"
      - "--class"
      - "org.apache.spark.examples.SparkPi"
      - "--conf"
      - "spark.kubernetes.container.image=docker.io/apache/spark:3.5.0"
      - "--conf"
      - "spark.kubernetes.namespace=spark-namespace"
      - "--conf"
      - "spark.kubernetes.authenticate.driver.serviceAccountName=spark-service-account"
      - "--conf"
      - "spark.eventLog.enabled=true"
      - "--conf"
      - "spark.eventLog.dir=/mnt/spark-logs"
      - "--conf"
      - "spark.history.fs.logDirectory=/mnt/spark-logs"
      - "--conf"
      - "spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-logs.options.claimName=spark-work-dir-claim"
      - "--conf"
      - "spark.kubernetes.driver.volumes.persistentVolumeClaim.spark-logs.mount.path=/mnt/spark-logs"
      - "--conf"
      - "spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-logs.options.claimName=spark-work-dir-claim"
      - "--conf"
      - "spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-logs.mount.path=/mnt/spark-logs"
      - "local:///opt/spark/examples/jars/spark-examples_2.12-3.5.0.jar"
    volumeMounts:
      - name: spark-logs
        mountPath: /mnt/spark-logs
  volumes:
    - name: spark-logs
      persistentVolumeClaim:
        claimName: spark-work-dir-claim
